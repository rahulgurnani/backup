There is much work on name transliteration and its inte.g.ation in larger MT systems CITATION .
We decode using Pharaoh CITATION .
Word alignment is done with GIZA++ CITATION .
The first 200 sentences in the 2002 MTEval test set were used for Minimum Error Training (MERT) CITATION .
Scientists CITATION describe a dictionary-based technique for translating OOV words in SMT .
6 We report results in terms of case-insensitive 4-gram BLEU CITATION scores .
This is especially true for languages with rich morphology such as Spanish, Catalan, and Serbian CITATION and Arabic CITATION .
We address some of these challenges in our baseline system by removing all diacritics, normalizing Alif and Ya forms, and tokenizing Arabic text in the highly competitive Arabic Treebank scheme CITATION .
All evaluated systems use the same surface trigram language model, trained on approximately 340 million words from the English Gigaword corpus CITATION using the SRILM toolkit CITATION .
Scientists CITATION address spelling-variant OOVs in MT through online re-tokenization into letters and combination with a word-based system .
Some previous approaches anticipate OOV words that are potentially morphologically related to in-vocabulary (INV) words CITATION .
Jewish Law documents written in Hebrew are known to be rich in ambiguous abbreviations CITATION .
In our previous research CITATION, we developed a prototype abbreviation disambiguation system for Jewish Law documents written in Hebrew, without using any ML method .
The numerical sum of the numerical values attributed to the Hebrew letters forming the abbreviation CITATION .
The one sense per discourse hypothesis (OS) was introduced by Scientists CITATION .
Systems developed by Pakhomov CITATION, Scientists CITATION and Scientists CITATION achieved 84% to 98% accuracy .
Yosef CITATION .
Active learning (AL) can be employed to reduce the costs of corpus annotation CITATION .
The easiest solution is to normalize by sentence length, as has been done previously CITATION .
We follow Engelson & Dagan CITATION in the implementation of vote entropy for sentence selection using these models .
In the context of parse tree annotation, Hwa CITATION estimates cost using the number of constituents needing labeling and Osborne & Baldridge CITATION use a measure related to the number of possible parses .
One exception is CITATION (discussed later) which compares the cost of manual rule writing with AL-based annotation for noun phrase chunking .
In contrast to the model presented by Ngai and Yarowsky CITATION, which predicts monetary cost given time spent, this model estimates time spent from characteristics of a sentence .
In prior work, we describe such a cost model for POS annotation on the basis of the time required for annotation CITATION .
Perhaps the best known are Query by Committee (QBC) CITATION and uncertainty sampling (or Query by Uncertainty, QBU) CITATION .
Our implementation of QBC employs a committee of three MEMM taggers to balance computational cost and diversity, following Scientists CITATION .
The features used in this work are typical for modern MEMM POS tagging and are mostly based on work by Toutanova and Manning CITATION .
Though there has been a growing interest in semi-supervised learning CITATION, it is in an early phase of development .
Previous domain resources include WordNet CITATION and HowNet CITATION, among others .
In this study, the 12 domains in Table 1 are used following CITATION (H&K hereafter) 1 .
Previous text cate.g.rization methods like Joachims CITATION and Schapire and Singer CITATION are mostly based on machine learning .
Ko and Seo CITATION automatically collect training data using a large amount of unlabeled data and a small amount of seed information .
This is consistent with Scientists CITATION, who claim that only positive evidence matter in cate.g.rization .
Scientists CITATION prepare representative words for each class, by which they collect initial training data to build classifier .
Scientists CITATION show the effectiveness of domain information for WSD .
Scientists CITATION use domain tags to extract MWEs .
We have implemented a Mixture Model POMDP architecture as a multi-state version of the DIPPER "Information State Update" dialogue manager CITATION .
An alternative is to apply automatically learned reordering rules to the test sentences before decoding CITATION .
Our translation system is based on the CMU SMT decoder as described in CITATION .
We used the Pharaoh/Moses package CITATION to extract and score phrase pairs using the grow-diag-final extraction method .
To accelerate the training of word alignment models we implemented a distributed version of GIZA++ CITATION, based on the latest version of GIZA++ and a parallel version developed at Peking University CITATION .
In this paper we report results using the BLEU metric CITATION, however as the evaluation criterion in GALE is HTER CITATION, we also report in TER CITATION .
Every outgoing edge of a node is scored with the relative frequency of the pattern used on the following sub path (For details see CITATION) .
We trained separate open vocabulary language models for each source and interpolated them using the SRI Language Modeling Toolkit CITATION .
Our preprocessing steps include tokenization on the English side and for Chinese: automatic word se.g.entation using the revised version of the Stanford Chinese Word Se.g.enter 2 CITATION from 2007, replacement of traditional by simplified Chinese characters and 2-byte to 1-byte ASCII character normalization .
In order to find an optimal set of weights, we use MER training as described in CITATION, which uses rescoring of the top n hypotheses to maximize an evaluation metric like BLEU or TER .
The BLEU oracle sentences were found using the dynamic-programming algorithm given in Scientists CITATION and measured using Philipp Koehn'seval-uation script .
In Model II, the semi-supervised setup, the training data is used to initialize the Expectation-Maximization (EM) algorithm CITATION and the unlabeled data, described in Section 3.1, updates the initial estimates .
225 words were selected for manual annotation as homograph or non-homograph by random sampling of words that were on the above list and used in prior psycholinguistic studies of homographs CITATION or on the Academic Word List CITATION .
However, making fine-grained sense distinctions for words with multiple closely-related meanings is a subjective task CITATION, which makes it difficult and error-prone .
Lexical ambiguity resolution is an important research problem for the fields of information retrieval and machine translation CITATION .
Fine-grained sense distinctions aren't necessary for many tasks, thus a possibly-simpler alternative is lexical disambiguation at the level of homographs CITATION .
The above two work was further advanced by Bunescu and Mooney CITATION who argued that the information to extract a relation between two entities can be typically captured by the shortest path between them in the dependency graph .
In the feature-based framework, Kambhatla CITATION employed ME models to combine diverse lexical, syntactic and semantic features derived from word, entity type, mention level, overlap, dependency and parse tree .
Scientists CITATION proposed a kernel over two parse trees, which recursively matched nodes from roots to leaves in a top-down manner .
Based on his work, Scientists CITATION further incorporated the base phrase chunking information and semi-automatically collected country name list and personal relative trigger word list .
Later, Scientists CITATION developed a composite kernel that combined parse tree kernel with entity kernel and Scientists CITATION experimented with a context-sensitive kernel by automatically determining context-sensitive tree spans .
Scientists CITATION defined an improved edit distance kernel over the original Chinese string representation around particular entities .
It is not difficult to list all of those characters that have the same or similar pronunciations, e.g., "t^AI" and ""fAI", if we have a machine readable lexicon that provides information about pronunciations of characters and when we ignore special patterns for tone sandhi in Chinese CITATION .
Bong-Foo Chu, selected a set of 24 basic elements in Chinese characters, and proposed a set of rules to decompose Chinese characters into elements that belong to this set of building blocks CITATION .
Figure 4 illustrates possible layouts of the components in Chinese characters that were adopted by the Cangjie method CITATION .
There are more than 22000 different characters in large corpus of Chinese documents CITATION, so directly computing the similarity between images of these characters demands a lot of computation .
Taft, Zhu, and Peng CITATION investigated the effects of positions of radicals on subjects' lexical decisions and naming responses .
Yeh and Li CITATION studied how similar characters influenced the judgments made by skilled readers of Chinese .
In this case, the "best" answer may be chosen by the votes, or alternatively by automatically predicting answer quality (e.g., CITATION or CITATION) .
• Cate.g.ry Features: We hypothesized that user behavior (and asker satisfaction) varies by topical question cate.g.ry, as recently shown in reference CITATION .
While information seeker satisfaction has been studied in ad-hoc IR context (see CITATION for an overview), previous studies have been limited by the lack of realistic user feedback .
In our recent work CITATION we have introduced a general model for predicting asker satisfaction in community question answering .
For more detailed treatment of user interactions in CQA see CITATION .
We now briefly review our ASP (Asker Satisfaction Prediction) framework that learns to classify whether a question has been satisfactorily answered, originally introduced in CITATION .
Furthermore, while automatic complex QA has been an active area of research, ranging from simple modification to factoid QA technique (e.g., CITATION) to knowledge intensive approaches for specialized domains, the technology does not yet exist to automatically answer open domain, complex, and subjective questions .
Classification Algorithms: We experimented with a variety of classifiers in the Weka framework CITATION .
However more recent results have shown that it can indeed improve parser performance CITATION .
Two previous papers would seem to address this issue: the work by Scientists CITATION and McScientists CITATION .
2 A close second (1% behind) was the parser of Bikel CITATION .
While self-training has worked in several domains, the early results on self-training for parsing were ne.g.tive CITATION .
Section three describes our main experiment on standard test data CITATION .
Cle.g. and Shepherd CITATION do not provide separate precision and recall numbers .
In contrast, the out-of-vocabulary rate of biomedical abstracts given the same lexicon is significantly higher at about 25% CITATION .
Lease and Charniak CITATION achieve their results using small amounts of hand-annotated biomedical part-of-speech-tagged data and also explore other possible sources or information .
Scientists , 1993)) and then self-training on a second type of data in order to adapt the parser to the second domain .
So, for example, McScientists CITATION found that the data from the handannotated WSJ data should be considered at least five times more important than NANC data on an event by event level .
However, several very good current parsers were not available when this paper was written (e.g., the Berkeley Parser CITATION) .
Bacchiani and Roark train the Roark parser CITATION on trees from the Brown treebank and then self-train and test on data from Wall Street Journal .
1 Scientists CITATION generally found that self-training does not work, but found that it does help if the baseline results were sufficiently bad .
Speech repairs are common in spontaneous speech - one study found 30% of dialogue turns contained repairs CITATION and another study found one repair every 4.8 seconds CITATION .
Recent advances in recognizing spontaneous speech with repairs CITATION have used parsing approaches on transcribed speech to account for the structure inherent in speech repairs at the word level and above .
I I Figure 1 : Standard tree repair structure, with -UNF propagation as in CITATION shown in brackets .
Figure 1 also shows, in brackets, the augmented annotation used by Scientists CITATION .
The approach used by CITATION works because the information about the transition to an error state is propagated up the tree, in the form of the -UNF tags .
With this representation, the problem noticed by Hale and colleagues CITATION has been solved in a different way, by incrementally building up left-branching rather than right-branching structure, so that only a single special error rule is required at the end of the constituent .
To make a fair comparison to the CYK baseline of CITATION, the recognizer was given correct part-of-speech tags as input along with words .
The TAG system CITATION achieves a higher EDIT-F score, largely as a result of its explicit tracking of overlapping words between reparanda and alterations .
In order to obtain a linguistically plausible right-corner transform representation of incomplete constituents, the Switchboard corpus is subjected to a pre-process transform to introduce binary-branching nonterminal projections, and fold empty cate.g.ries into nonterminal symbols in a manner similar to that proposed by Johnson CITATION and Klein and Manning CITATION .
The speech repair terminology used here follows that of Shriberg CITATION .
The incomplete constituent cate.g.ries created by the right corner transform are similar in form and meaning to non-constituent cate.g.ries used in Combinatorial Cate.g.rial Grammars (CCGs) CITATION .
The classifiers generally mimic human judgements in that accuracy is much lower in the three-way classification task - a pattern concurring with past observations (cf.Esuli and Sebastiani CITATION; Andreevskaia and Bergler CITATION) .
Non-neutral adjectives were extracted from WordNet and assigned fuzzy sentiment cate.g.ry member-ship/centrality scores and tags in Andreevskaia and Bergler CITATION .
The semi-supervised learning method in Esuli and Sebastiani CITATION involves constructing a training set of non-neutral words using WordNet synsets, glosses and examples by iteratively adding syn- and antonyms to it and learning a term classifier on the glosses of the terms in the training set .
Esuli and Sebastiani CITATION used the method to cover objective (n) cases .
